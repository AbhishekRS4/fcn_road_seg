{
    "TARGET_IMAGE_SIZE" : [480, 640],
    "INPUTS_PATH" : "/home/abhishek/Desktop/datasets/camvid/inputs_resized/",
    "MASKS_PATH" : "/home/abhishek/Desktop/datasets/camvid/masks_resized/",
    "VGG_PATH" : "/home/abhishek/Desktop/deep_learning/computer_vision/vgg_model/vgg16.npy", 
    "NUM_CHANNELS" : 3,
    "TRAINING" : 1,
    "COLOR_MASK" : [0, 255, 0],
    "num_classes" : 2,
    "kernel_size" : [3, 3],
    "upsample_kernel_size" : [2, 2],
    "pool_size" : [2, 2],
    "strides" : [1, 1],
    "reduction_strides" : [2, 2],
    "padding" : "same",
    "data_format" : "channels_first",
    "learning_rate" : 0.0001,
    "num_epochs" : 250,
    "batch_size" : 8,
    "model_metrics" : ["fcn8_metrics.npy", "fcn16_metrics.npy", "fcn32_metrics.npy"],
    "model_file" : ["fcn8_model", "fcn16_model", "fcn32_model"],
    "model_directory" : ["model_fcn8_ce_", "model_fcn16_ce_", "model_fcn32_ce_", "model_fcn8_dice_", "model_fcn16_dice_", "model_fcn32_dice_", "model_fcn8_both_", "model_fcn16_both_", "model_fcn32_both_"],
    "model_to_use" : 0
}
